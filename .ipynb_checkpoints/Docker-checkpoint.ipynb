{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e3ce5c-d92d-47a5-b9e8-7cd810cea276",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0c29493-92d2-4db7-883c-5a7d6a46f61c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoBrokersAvailable",
     "evalue": "NoBrokersAvailable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoBrokersAvailable\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      7\u001b[0m client \u001b[38;5;241m=\u001b[39m tweepy\u001b[38;5;241m.\u001b[39mClient(bearer_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAAAAAAAAAAAAAAAAAAAAADBrtAEAAAAAH9zPkDa7P933LXmnbgmfZ8hr5Nc\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m3D8lRdFlgYSNY8YjU5og5oKgD1jKgwFQdA9xbfSgi5DPbEwyTWVI\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m producer \u001b[38;5;241m=\u001b[39m KafkaProducer()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# producer.flush()\u001b[39;00m\n\u001b[0;32m     10\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcovid\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\kafka\\producer\\kafka.py:381\u001b[0m, in \u001b[0;36mKafkaProducer.__init__\u001b[1;34m(self, **configs)\u001b[0m\n\u001b[0;32m    378\u001b[0m reporters \u001b[38;5;241m=\u001b[39m [reporter() \u001b[38;5;28;01mfor\u001b[39;00m reporter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetric_reporters\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metrics \u001b[38;5;241m=\u001b[39m Metrics(metric_config, reporters)\n\u001b[1;32m--> 381\u001b[0m client \u001b[38;5;241m=\u001b[39m KafkaClient(metrics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metrics, metric_group_prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproducer\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    382\u001b[0m                      wakeup_timeout_ms\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_block_ms\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    383\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig)\n\u001b[0;32m    385\u001b[0m \u001b[38;5;66;03m# Get auto-discovered version from client if necessary\u001b[39;00m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapi_version\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\kafka\\client_async.py:244\u001b[0m, in \u001b[0;36mKafkaClient.__init__\u001b[1;34m(self, **configs)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapi_version\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    243\u001b[0m     check_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapi_version_auto_timeout_ms\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m--> 244\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapi_version\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_version(timeout\u001b[38;5;241m=\u001b[39mcheck_timeout)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\kafka\\client_async.py:927\u001b[0m, in \u001b[0;36mKafkaClient.check_version\u001b[1;34m(self, node_id, timeout, strict)\u001b[0m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;66;03m# Timeout\u001b[39;00m\n\u001b[0;32m    925\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    926\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m--> 927\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Errors\u001b[38;5;241m.\u001b[39mNoBrokersAvailable()\n",
      "\u001b[1;31mNoBrokersAvailable\u001b[0m: NoBrokersAvailable"
     ]
    }
   ],
   "source": [
    "from kafka import KafkaProducer\n",
    "import tweepy\n",
    "import datetime\n",
    "import time\n",
    "import json\n",
    "\n",
    "client = tweepy.Client(bearer_token='AAAAAAAAAAAAAAAAAAAAADBrtAEAAAAAH9zPkDa7P933LXmnbgmfZ8hr5Nc%3D8lRdFlgYSNY8YjU5og5oKgD1jKgwFQdA9xbfSgi5DPbEwyTWVI')\n",
    "producer = KafkaProducer()\n",
    "# producer.flush()\n",
    "query = 'basketball'\n",
    "start_time = datetime.datetime.utcnow() - datetime.timedelta(seconds=40)\n",
    "end_time = datetime.datetime.utcnow() - datetime.timedelta(seconds=30)\n",
    "\n",
    "while True:\n",
    "\n",
    "    tweets = client.search_recent_tweets(query=query,\n",
    "                                        tweet_fields=['context_annotations', 'created_at', 'lang'], \n",
    "                                        max_results=100, \n",
    "                                        start_time=start_time,\n",
    "                                        end_time=end_time)\n",
    "    start_time = end_time\n",
    "    end_time = start_time + datetime.timedelta(seconds=10)\n",
    "\n",
    "    for i,tweet in enumerate(tweets.data):\n",
    "        if tweet.lang == 'en':\n",
    "            tweet = json.dumps(tweet.text).encode('utf-8')\n",
    "            producer.send('covid', tweet)\n",
    "        print(f'Le {i}ème tweet a été envoyé à Kafka avec succès!')\n",
    "    print('Pause de 10 secondes!')\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a68f91db-913a-446f-ab1f-07b967f5c5a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoBrokersAvailable",
     "evalue": "NoBrokersAvailable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoBrokersAvailable\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m client \u001b[38;5;241m=\u001b[39m tweepy\u001b[38;5;241m.\u001b[39mClient(bearer_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAAAAAAAAAAAAAAAAAAAAADBrtAEAAAAAH9zPkDa7P933LXmnbgmfZ8hr5Nc\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m3D8lRdFlgYSNY8YjU5og5oKgD1jKgwFQdA9xbfSgi5DPbEwyTWVI\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m producer \u001b[38;5;241m=\u001b[39m KafkaProducer()\n\u001b[0;32m      3\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcovid\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\kafka\\producer\\kafka.py:381\u001b[0m, in \u001b[0;36mKafkaProducer.__init__\u001b[1;34m(self, **configs)\u001b[0m\n\u001b[0;32m    378\u001b[0m reporters \u001b[38;5;241m=\u001b[39m [reporter() \u001b[38;5;28;01mfor\u001b[39;00m reporter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetric_reporters\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metrics \u001b[38;5;241m=\u001b[39m Metrics(metric_config, reporters)\n\u001b[1;32m--> 381\u001b[0m client \u001b[38;5;241m=\u001b[39m KafkaClient(metrics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metrics, metric_group_prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproducer\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    382\u001b[0m                      wakeup_timeout_ms\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_block_ms\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    383\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig)\n\u001b[0;32m    385\u001b[0m \u001b[38;5;66;03m# Get auto-discovered version from client if necessary\u001b[39;00m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapi_version\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\kafka\\client_async.py:244\u001b[0m, in \u001b[0;36mKafkaClient.__init__\u001b[1;34m(self, **configs)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapi_version\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    243\u001b[0m     check_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapi_version_auto_timeout_ms\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m--> 244\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapi_version\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_version(timeout\u001b[38;5;241m=\u001b[39mcheck_timeout)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\kafka\\client_async.py:927\u001b[0m, in \u001b[0;36mKafkaClient.check_version\u001b[1;34m(self, node_id, timeout, strict)\u001b[0m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;66;03m# Timeout\u001b[39;00m\n\u001b[0;32m    925\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    926\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m--> 927\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Errors\u001b[38;5;241m.\u001b[39mNoBrokersAvailable()\n",
      "\u001b[1;31mNoBrokersAvailable\u001b[0m: NoBrokersAvailable"
     ]
    }
   ],
   "source": [
    "client = tweepy.Client(bearer_token=\"AAAAAAAAAAAAAAAAAAAAADBrtAEAAAAAH9zPkDa7P933LXmnbgmfZ8hr5Nc%3D8lRdFlgYSNY8YjU5og5oKgD1jKgwFQdA9xbfSgi5DPbEwyTWVI\")\n",
    "producer = KafkaProducer()\n",
    "query = \"covid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17506bd9-06d2-4e2c-811c-ed86f1529f6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KafkaTimeoutError",
     "evalue": "KafkaTimeoutError: Failed to update metadata after 60.0 secs.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKafkaTimeoutError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Envoi des messages à Kafka\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m messages:\n\u001b[1;32m---> 14\u001b[0m     producer\u001b[38;5;241m.\u001b[39msend(topic_name, value\u001b[38;5;241m=\u001b[39mmessage)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Attendre que tous les messages soient envoyés\u001b[39;00m\n\u001b[0;32m     17\u001b[0m producer\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\kafka\\producer\\kafka.py:576\u001b[0m, in \u001b[0;36mKafkaProducer.send\u001b[1;34m(self, topic, value, key, headers, partition, timestamp_ms)\u001b[0m\n\u001b[0;32m    574\u001b[0m key_bytes \u001b[38;5;241m=\u001b[39m value_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 576\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_on_metadata(topic, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_block_ms\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1000.0\u001b[39m)\n\u001b[0;32m    578\u001b[0m     key_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialize(\n\u001b[0;32m    579\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkey_serializer\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    580\u001b[0m         topic, key)\n\u001b[0;32m    581\u001b[0m     value_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialize(\n\u001b[0;32m    582\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue_serializer\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    583\u001b[0m         topic, value)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\kafka\\producer\\kafka.py:702\u001b[0m, in \u001b[0;36mKafkaProducer._wait_on_metadata\u001b[1;34m(self, topic, max_wait)\u001b[0m\n\u001b[0;32m    700\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m begin\n\u001b[0;32m    701\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m metadata_event\u001b[38;5;241m.\u001b[39mis_set():\n\u001b[1;32m--> 702\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Errors\u001b[38;5;241m.\u001b[39mKafkaTimeoutError(\n\u001b[0;32m    703\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to update metadata after \u001b[39m\u001b[38;5;132;01m%.1f\u001b[39;00m\u001b[38;5;124m secs.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (max_wait,))\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m topic \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\u001b[38;5;241m.\u001b[39munauthorized_topics:\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Errors\u001b[38;5;241m.\u001b[39mTopicAuthorizationFailedError(topic)\n",
      "\u001b[1;31mKafkaTimeoutError\u001b[0m: KafkaTimeoutError: Failed to update metadata after 60.0 secs."
     ]
    }
   ],
   "source": [
    "# Configuration du producteur Kafka\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers=['localhost:9092:9092'],\n",
    "    api_version=(0, 11, 5),\n",
    "    value_serializer=lambda x: json.dumps(x).encode('utf-8')\n",
    ")\n",
    "\n",
    "# Exemple d'envoi de messages\n",
    "topic_name = 'docker'  # Remplacez par le nom du topic Kafka auquel envoyer les messages\n",
    "messages = [{'key': 'value'}, {'key2': 'value2'}]  # Liste des messages à envoyer\n",
    "\n",
    "# Envoi des messages à Kafka\n",
    "for message in messages:\n",
    "    producer.send(topic_name, value=message)\n",
    "\n",
    "# Attendre que tous les messages soient envoyés\n",
    "producer.flush()\n",
    "\n",
    "# Fermer le producteur Kafka\n",
    "producer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "716524f6-238e-4bfb-b3a1-36982778d086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\pc\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\pc\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\pc\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\pc\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\pc\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8c70c22-08dc-487a-89b8-a1f4d939f9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "\n",
    "def pre_process_tweet(tweet):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    # tokenize and remove stop words and number\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)[1:]\n",
    "    tweet_tokens = [word for word in tweet_tokens if word.isalpha()]\n",
    "    tweet_tokens = [word for word in tweet_tokens if word.lower() != 'rt']\n",
    "    tweet = \" \".join([word for word in tweet_tokens if word not in stopwords.words('french')])\n",
    "\n",
    "    # remove \\n from the end after every sentence\n",
    "    tweet = tweet.strip('\\n')\n",
    "\n",
    "    # Remove any word that starts with the symbol @\n",
    "    tweet = \" \".join(filter(lambda x: x[0] != '@', tweet.split()))\n",
    "\n",
    "    # remove non utf-8 characters\n",
    "    tweet = bytes(tweet, 'utf-8').decode('utf-8','ignore')\n",
    "\n",
    "    # Remove any URL\n",
    "    tweet = re.sub(r\"http\\S+\", \"\", tweet)\n",
    "    tweet = re.sub(r\"www\\S+\", \"\", tweet)\n",
    "\n",
    "    # remove colons from the end of the sentences (if any) after removing url\n",
    "    tweet = tweet.strip()\n",
    "    tweet_len = len(tweet)\n",
    "    if tweet_len > 0:\n",
    "        if tweet[len(tweet) - 1] == ':':\n",
    "            tweet = tweet[:len(tweet) - 1]\n",
    "\n",
    "    # Remove any hash-tags symbols\n",
    "    tweet = tweet.replace('#', '')\n",
    "\n",
    "    # Convert every word to lowercase\n",
    "    tweet = tweet.lower()\n",
    "\n",
    "    # remove punctuations\n",
    "    tweet = tweet.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # trim extra spaces\n",
    "    tweet = \" \".join(tweet.split())\n",
    "\n",
    "    # lematize words\n",
    "    tweet = lemmatizer.lemmatize(tweet)\n",
    "\n",
    "    return(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82362bc2-98b0-4e10-8324-e8334ae39e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in c:\\users\\pc\\anaconda3\\lib\\site-packages (1.9.3)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from wordcloud) (1.26.4)\n",
      "Requirement already satisfied: pillow in c:\\users\\pc\\anaconda3\\lib\\site-packages (from wordcloud) (10.2.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\pc\\anaconda3\\lib\\site-packages (from wordcloud) (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf0daeb2-b337-4b6f-a714-2684ce266de2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoBrokersAvailable",
     "evalue": "NoBrokersAvailable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoBrokersAvailable\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      7\u001b[0m client \u001b[38;5;241m=\u001b[39m tweepy\u001b[38;5;241m.\u001b[39mClient(bearer_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAAAAAAAAAAAAAAAAAAAAADBrtAEAAAAAmajHrmqlNlWyrvJYJKBb0l1CS6I\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m3DzFwn8Wx0uz3XStUYRiQTy0nFpH2eLN7LJpk2skgCIFtmEcLOUE\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m producer \u001b[38;5;241m=\u001b[39m KafkaProducer()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# producer.flush()\u001b[39;00m\n\u001b[0;32m     10\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcup world\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\kafka\\producer\\kafka.py:381\u001b[0m, in \u001b[0;36mKafkaProducer.__init__\u001b[1;34m(self, **configs)\u001b[0m\n\u001b[0;32m    378\u001b[0m reporters \u001b[38;5;241m=\u001b[39m [reporter() \u001b[38;5;28;01mfor\u001b[39;00m reporter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetric_reporters\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metrics \u001b[38;5;241m=\u001b[39m Metrics(metric_config, reporters)\n\u001b[1;32m--> 381\u001b[0m client \u001b[38;5;241m=\u001b[39m KafkaClient(metrics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metrics, metric_group_prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproducer\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    382\u001b[0m                      wakeup_timeout_ms\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_block_ms\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    383\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig)\n\u001b[0;32m    385\u001b[0m \u001b[38;5;66;03m# Get auto-discovered version from client if necessary\u001b[39;00m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapi_version\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\kafka\\client_async.py:244\u001b[0m, in \u001b[0;36mKafkaClient.__init__\u001b[1;34m(self, **configs)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapi_version\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    243\u001b[0m     check_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapi_version_auto_timeout_ms\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m--> 244\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapi_version\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_version(timeout\u001b[38;5;241m=\u001b[39mcheck_timeout)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\kafka\\client_async.py:927\u001b[0m, in \u001b[0;36mKafkaClient.check_version\u001b[1;34m(self, node_id, timeout, strict)\u001b[0m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;66;03m# Timeout\u001b[39;00m\n\u001b[0;32m    925\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    926\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m--> 927\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Errors\u001b[38;5;241m.\u001b[39mNoBrokersAvailable()\n",
      "\u001b[1;31mNoBrokersAvailable\u001b[0m: NoBrokersAvailable"
     ]
    }
   ],
   "source": [
    "from kafka import KafkaProducer\n",
    "import tweepy\n",
    "import datetime\n",
    "import time\n",
    "import json\n",
    "\n",
    "client = tweepy.Client(bearer_token='AAAAAAAAAAAAAAAAAAAAADBrtAEAAAAAmajHrmqlNlWyrvJYJKBb0l1CS6I%3DzFwn8Wx0uz3XStUYRiQTy0nFpH2eLN7LJpk2skgCIFtmEcLOUE')\n",
    "producer = KafkaProducer()\n",
    "# producer.flush()\n",
    "query = 'cup world'\n",
    "start_time = datetime.datetime.utcnow() - datetime.timedelta(seconds=40)\n",
    "end_time = datetime.datetime.utcnow() - datetime.timedelta(seconds=30)\n",
    "\n",
    "while True:\n",
    "\n",
    "    tweets = client.search_recent_tweets(query=query,\n",
    "                                        tweet_fields=['context_annotations', 'created_at', 'lang'], \n",
    "                                        max_results=100, \n",
    "                                        start_time=start_time,\n",
    "                                        end_time=end_time)\n",
    "    start_time = end_time\n",
    "    end_time = start_time + datetime.timedelta(seconds=10)\n",
    "\n",
    "    for i,tweet in enumerate(tweets.data):\n",
    "        if tweet.lang == 'en':\n",
    "            tweet = json.dumps(tweet.text).encode('utf-8')\n",
    "            producer.send('covid', tweet)\n",
    "        print(f'Le {i}ème tweet a été envoyé à Kafka avec succès!')\n",
    "    print('Pause de 10 secondes!')\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ee97991-60bc-40d5-b144-7568c5170865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "\n",
    "def pre_process_tweet(tweet):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    # tokenize and remove stop words and number\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)[1:]\n",
    "    tweet_tokens = [word for word in tweet_tokens if word.isalpha()]\n",
    "    tweet_tokens = [word for word in tweet_tokens if word.lower() != 'rt']\n",
    "    tweet = \" \".join([word for word in tweet_tokens if word not in stopwords.words('french')])\n",
    "\n",
    "    # remove \\n from the end after every sentence\n",
    "    tweet = tweet.strip('\\n')\n",
    "\n",
    "    # Remove any word that starts with the symbol @\n",
    "    tweet = \" \".join(filter(lambda x: x[0] != '@', tweet.split()))\n",
    "\n",
    "    # remove non utf-8 characters\n",
    "    tweet = bytes(tweet, 'utf-8').decode('utf-8','ignore')\n",
    "\n",
    "    # Remove any URL\n",
    "    tweet = re.sub(r\"http\\S+\", \"\", tweet)\n",
    "    tweet = re.sub(r\"www\\S+\", \"\", tweet)\n",
    "\n",
    "    # remove colons from the end of the sentences (if any) after removing url\n",
    "    tweet = tweet.strip()\n",
    "    tweet_len = len(tweet)\n",
    "    if tweet_len > 0:\n",
    "        if tweet[len(tweet) - 1] == ':':\n",
    "            tweet = tweet[:len(tweet) - 1]\n",
    "\n",
    "    # Remove any hash-tags symbols\n",
    "    tweet = tweet.replace('#', '')\n",
    "\n",
    "    # Convert every word to lowercase\n",
    "    tweet = tweet.lower()\n",
    "\n",
    "    # remove punctuations\n",
    "    tweet = tweet.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # trim extra spaces\n",
    "    tweet = \" \".join(tweet.split())\n",
    "\n",
    "    # lematize words\n",
    "    tweet = lemmatizer.lemmatize(tweet)\n",
    "\n",
    "    return(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cf4a47-0ecf-4139-997f-94ce1e8cbc45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
